#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test Audio Slice Analysis - Ki·ªÉm tra file ƒë∆∞·ª£c c·∫Øt
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import logging
import librosa
import numpy as np

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def analyze_sliced_audio():
    """Ph√¢n t√≠ch file audio ƒë√£ ƒë∆∞·ª£c c·∫Øt"""
    try:
        # File ƒë∆∞·ª£c c·∫Øt t·ª´ workflow
        sliced_file = "D:\\singing scoring AI\\src\\ai\\..\\..\\output\\optimized_processing\\karaoke_slice_Waiting For You_10.8s_20.0s.wav"
        
        if not os.path.exists(sliced_file):
            logger.error(f"File c·∫Øt kh√¥ng t·ªìn t·∫°i: {sliced_file}")
            return False
        
        logger.info(f"üîç Ph√¢n t√≠ch file ƒë√£ c·∫Øt: {os.path.basename(sliced_file)}")
        
        # Load audio
        audio, sr = librosa.load(sliced_file, sr=22050)
        duration = len(audio) / sr
        
        logger.info(f"Audio info: {duration:.2f}s, {sr} Hz, {len(audio)} samples")
        
        # Ph√¢n t√≠ch energy theo th·ªùi gian
        hop_length = 512
        frame_length = 2048
        
        # RMS Energy
        rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
        
        # Spectral Centroid
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr, hop_length=hop_length)[0]
        
        # Zero Crossing Rate
        zcr = librosa.feature.zero_crossing_rate(audio, frame_length=frame_length, hop_length=hop_length)[0]
        
        # T√¨m v·ªã tr√≠ c√≥ voice
        voice_threshold = np.percentile(rms, 30)
        voice_frames = np.where(rms > voice_threshold)[0]
        
        if len(voice_frames) > 0:
            # Chuy·ªÉn frames th√†nh th·ªùi gian
            times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
            voice_times = times[voice_frames]
            
            logger.info(f"üìä Ph√¢n t√≠ch voice trong file c·∫Øt:")
            logger.info(f"   Total frames: {len(rms)}")
            logger.info(f"   Voice frames: {len(voice_frames)}")
            logger.info(f"   Voice threshold: {voice_threshold:.4f}")
            
            if len(voice_times) > 0:
                first_voice_time = voice_times[0]
                last_voice_time = voice_times[-1]
                
                logger.info(f"   First voice at: {first_voice_time:.2f}s")
                logger.info(f"   Last voice at: {last_voice_time:.2f}s")
                
                # Ph√¢n t√≠ch chi ti·∫øt t·ª´ng ƒëo·∫°n
                logger.info(f"\nüìà Ph√¢n t√≠ch chi ti·∫øt:")
                for i in range(0, len(rms), len(rms)//10):  # 10 ƒëo·∫°n
                    start_time = i * hop_length / sr
                    end_time = min((i + len(rms)//10) * hop_length / sr, duration)
                    segment_rms = rms[i:i+len(rms)//10]
                    segment_centroid = spectral_centroids[i:i+len(rms)//10]
                    
                    avg_rms = np.mean(segment_rms)
                    avg_centroid = np.mean(segment_centroid)
                    
                    has_voice = avg_rms > voice_threshold
                    
                    logger.info(f"   {start_time:.1f}s - {end_time:.1f}s: RMS={avg_rms:.4f}, Centroid={avg_centroid:.1f}Hz, Voice={'YES' if has_voice else 'NO'}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói ph√¢n t√≠ch: {e}")
        import traceback
        traceback.print_exc()
        return False

def analyze_original_voice_position():
    """Ph√¢n t√≠ch v·ªã tr√≠ voice trong file g·ªëc"""
    try:
        from src.ai.smart_voice_detector import SmartVoiceDetector
        
        # File g·ªëc
        original_file = "C:\\Users\\admin\\Downloads\\Waiting For You.mp3"
        
        if not os.path.exists(original_file):
            logger.error(f"File g·ªëc kh√¥ng t·ªìn t·∫°i: {original_file}")
            return False
        
        logger.info(f"üîç Ph√¢n t√≠ch v·ªã tr√≠ voice trong file g·ªëc...")
        
        # Smart Voice Detector
        detector = SmartVoiceDetector()
        segments = detector.detect_voice_activity(original_file)
        
        if segments:
            first_segment = segments[0]
            logger.info(f"üìä Voice segments trong file g·ªëc:")
            logger.info(f"   First segment: {first_segment['start']:.2f}s - {first_segment['end']:.2f}s")
            
            # Ph√¢n t√≠ch chi ti·∫øt v√πng xung quanh
            start_time = first_segment['start']
            end_time = first_segment['end']
            
            # Load audio v√† ph√¢n t√≠ch v√πng xung quanh
            audio, sr = librosa.load(original_file, sr=22050)
            
            # Ph√¢n t√≠ch 5s tr∆∞·ªõc v√† sau v·ªã tr√≠ detected
            analysis_start = max(0, start_time - 5)
            analysis_end = min(len(audio)/sr, start_time + 10)
            
            logger.info(f"\nüìà Ph√¢n t√≠ch v√πng xung quanh {start_time:.2f}s:")
            logger.info(f"   Analysis range: {analysis_start:.2f}s - {analysis_end:.2f}s")
            
            # C·∫Øt audio ƒë·ªÉ ph√¢n t√≠ch
            start_sample = int(analysis_start * sr)
            end_sample = int(analysis_end * sr)
            analysis_audio = audio[start_sample:end_sample]
            
            # Ph√¢n t√≠ch energy
            hop_length = 512
            rms = librosa.feature.rms(y=analysis_audio, frame_length=2048, hop_length=hop_length)[0]
            
            # T√¨m v·ªã tr√≠ voice th·ª±c s·ª±
            voice_threshold = np.percentile(rms, 25)
            voice_frames = np.where(rms > voice_threshold)[0]
            
            if len(voice_frames) > 0:
                times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
                voice_times = times[voice_frames] + analysis_start
                
                logger.info(f"   Voice threshold: {voice_threshold:.4f}")
                logger.info(f"   Voice frames: {len(voice_frames)}")
                logger.info(f"   First voice at: {voice_times[0]:.2f}s")
                logger.info(f"   Last voice at: {voice_times[-1]:.2f}s")
                
                # So s√°nh v·ªõi v·ªã tr√≠ detected
                detected_start = start_time
                actual_start = voice_times[0]
                error = abs(detected_start - actual_start)
                
                logger.info(f"\nüéØ So s√°nh:")
                logger.info(f"   Detected start: {detected_start:.2f}s")
                logger.info(f"   Actual start: {actual_start:.2f}s")
                logger.info(f"   Error: {error:.2f}s")
                
                if error > 2.0:
                    logger.warning(f"‚ö†Ô∏è Voice detection c√≥ sai s·ªë l·ªõn: {error:.2f}s")
                    return False
                else:
                    logger.info(f"‚úÖ Voice detection ch√≠nh x√°c: {error:.2f}s")
                    return True
        
        return False
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói ph√¢n t√≠ch: {e}")
        return False

if __name__ == "__main__":
    print("=== TEST AUDIO SLICE ANALYSIS ===")
    
    # Ph√¢n t√≠ch file ƒë√£ c·∫Øt
    print("\n1. Phan tich file da cat...")
    slice_success = analyze_sliced_audio()
    
    # Phan tich vi tri voice goc
    print("\n2. Phan tich vi tri voice goc...")
    original_success = analyze_original_voice_position()
    
    # Ket qua
    print("\n=== KET QUA ===")
    print(f"Slice Analysis: {'OK' if slice_success else 'ERROR'}")
    print(f"Original Analysis: {'OK' if original_success else 'ERROR'}")
    
    if slice_success and original_success:
        print("\nDA PHAN TICH FILE AUDIO!")
    else:
        print("\nCO VAN DE VOI FILE AUDIO!")
