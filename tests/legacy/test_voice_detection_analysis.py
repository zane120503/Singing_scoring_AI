#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test Voice Detection Analysis - PhÃ¢n tÃ­ch chi tiáº¿t vá»‹ trÃ­ giá»ng hÃ¡t
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import logging
import librosa
import numpy as np
import matplotlib.pyplot as plt

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def analyze_voice_precisely():
    """PhÃ¢n tÃ­ch chÃ­nh xÃ¡c vá»‹ trÃ­ giá»ng hÃ¡t trong file Waiting For You"""
    try:
        # File gá»‘c
        audio_file = "C:\\Users\\admin\\Downloads\\Waiting For You.mp3"
        
        if not os.path.exists(audio_file):
            logger.error(f"File khÃ´ng tá»“n táº¡i: {audio_file}")
            return False
        
        logger.info(f"ðŸ” PhÃ¢n tÃ­ch chÃ­nh xÃ¡c vá»‹ trÃ­ giá»ng hÃ¡t...")
        logger.info(f"File: {audio_file}")
        
        # Load audio
        audio, sr = librosa.load(audio_file, sr=22050)
        duration = len(audio) / sr
        
        logger.info(f"Audio info: {duration:.2f}s, {sr} Hz, {len(audio)} samples")
        
        # PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng giÃ¢y
        hop_length = 512
        frame_length = 2048
        
        # TÃ­nh cÃ¡c features
        rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr, hop_length=hop_length)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, hop_length=hop_length)[0]
        zcr = librosa.feature.zero_crossing_rate(audio, frame_length=frame_length, hop_length=hop_length)[0]
        
        # Chuyá»ƒn frames thÃ nh thá»i gian
        times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
        
        # PhÃ¢n tÃ­ch tá»«ng giÃ¢y Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ giá»ng hÃ¡t thá»±c sá»±
        logger.info(f"\nðŸ“Š PhÃ¢n tÃ­ch tá»«ng giÃ¢y Ä‘á»ƒ tÃ¬m giá»ng hÃ¡t:")
        
        voice_start_candidates = []
        
        # PhÃ¢n tÃ­ch 30 giÃ¢y Ä‘áº§u
        for i in range(min(30, len(rms))):
            start_time = i * hop_length / sr
            end_time = min((i + 1) * hop_length / sr, duration)
            
            # Láº¥y features cá»§a giÃ¢y nÃ y
            segment_rms = rms[i]
            segment_centroid = spectral_centroids[i]
            segment_rolloff = spectral_rolloff[i]
            segment_zcr = zcr[i]
            
            # PhÃ¢n tÃ­ch harmonic content
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # Harmonic-percussive separation
            try:
                harmonic, percussive = librosa.effects.hpss(segment_audio)
                harmonic_energy = np.mean(np.abs(harmonic))
                percussive_energy = np.mean(np.abs(percussive))
                harmonic_ratio = harmonic_energy / (harmonic_energy + percussive_energy + 1e-8)
            except:
                harmonic_ratio = 0.5
            
            # MFCC Ä‘á»ƒ phÃ¡t hiá»‡n voice characteristics
            try:
                mfccs = librosa.feature.mfcc(y=segment_audio, sr=sr, n_mfcc=13)
                mfcc_mean = np.mean(mfccs[0])
                mfcc_std = np.std(mfccs[0])
            except:
                mfcc_mean = 0
                mfcc_std = 0
            
            # Äiá»u kiá»‡n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ³ giá»ng hÃ¡t
            has_voice = (
                segment_rms > 0.08 and  # Energy Ä‘á»§ cao
                segment_centroid > 1000 and segment_centroid < 4000 and  # Voice frequency range
                segment_rolloff > 1000 and  # CÃ³ high frequency content
                harmonic_ratio > 0.6 and  # Harmonic content cao (voice cÃ³ harmonic)
                mfcc_std > 50  # MFCC variation (voice cÃ³ variation)
            )
            
            if has_voice:
                voice_start_candidates.append({
                    'time': start_time,
                    'rms': segment_rms,
                    'centroid': segment_centroid,
                    'rolloff': segment_rolloff,
                    'harmonic_ratio': harmonic_ratio,
                    'mfcc_std': mfcc_std
                })
            
            # Log chi tiáº¿t cho 20 giÃ¢y Ä‘áº§u
            if start_time < 20:
                logger.info(f"   {start_time:.1f}s: RMS={segment_rms:.4f}, Centroid={segment_centroid:.1f}Hz, Rolloff={segment_rolloff:.1f}Hz, Harmonic={harmonic_ratio:.3f}, MFCC_std={mfcc_std:.1f}, Voice={'YES' if has_voice else 'NO'}")
        
        # TÃ¬m vá»‹ trÃ­ giá»ng hÃ¡t báº¯t Ä‘áº§u thá»±c sá»±
        if voice_start_candidates:
            # Láº¥y vá»‹ trÃ­ Ä‘áº§u tiÃªn cÃ³ voice
            first_voice = voice_start_candidates[0]
            logger.info(f"\nðŸŽ¯ Vá»‹ trÃ­ giá»ng hÃ¡t thá»±c sá»±:")
            logger.info(f"   First voice detected at: {first_voice['time']:.2f}s")
            logger.info(f"   RMS: {first_voice['rms']:.4f}")
            logger.info(f"   Centroid: {first_voice['centroid']:.1f}Hz")
            logger.info(f"   Harmonic ratio: {first_voice['harmonic_ratio']:.3f}")
            
            return first_voice['time']
        else:
            logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y vá»‹ trÃ­ giá»ng hÃ¡t!")
            return None
        
    except Exception as e:
        logger.error(f"âŒ Lá»—i phÃ¢n tÃ­ch: {e}")
        import traceback
        traceback.print_exc()
        return None

def create_precise_voice_detector():
    """Táº¡o Precise Voice Detector dá»±a trÃªn phÃ¢n tÃ­ch"""
    try:
        from src.ai.improved_smart_voice_detector import ImprovedSmartVoiceDetector
        
        # PhÃ¢n tÃ­ch Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ chÃ­nh xÃ¡c
        precise_voice_start = analyze_voice_precisely()
        
        if precise_voice_start is None:
            logger.error("âŒ KhÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh vá»‹ trÃ­ giá»ng hÃ¡t chÃ­nh xÃ¡c")
            return False
        
        logger.info(f"ðŸŽ¯ Táº¡o Precise Voice Detector vá»›i voice start: {precise_voice_start:.2f}s")
        
        # Test vá»›i Improved Smart Voice Detector
        detector = ImprovedSmartVoiceDetector()
        test_file = "C:\\Users\\admin\\Downloads\\Waiting For You.mp3"
        
        segments = detector.detect_voice_activity(test_file)
        
        if segments:
            detected_start = segments[0]['start']
            error = abs(detected_start - precise_voice_start)
            
            logger.info(f"\nðŸ“Š So sÃ¡nh káº¿t quáº£:")
            logger.info(f"   Precise voice start: {precise_voice_start:.2f}s")
            logger.info(f"   Detected voice start: {detected_start:.2f}s")
            logger.info(f"   Error: {error:.2f}s")
            
            if error < 1.0:
                logger.info(f"âœ… CHÃNH XÃC (sai sá»‘: {error:.2f}s)")
                return True
            else:
                logger.warning(f"âŒ KHÃ”NG CHÃNH XÃC (sai sá»‘: {error:.2f}s)")
                return False
        
        return False
        
    except Exception as e:
        logger.error(f"âŒ Lá»—i táº¡o detector: {e}")
        return False

if __name__ == "__main__":
    print("=== TEST VOICE DETECTION ANALYSIS ===")
    
    # PhÃ¢n tÃ­ch chÃ­nh xÃ¡c vá»‹ trÃ­ giá»ng hÃ¡t
    print("\n1. PhÃ¢n tÃ­ch chÃ­nh xÃ¡c vá»‹ trÃ­ giá»ng hÃ¡t...")
    precise_analysis = analyze_voice_precisely()
    
    # Táº¡o precise voice detector
    print("\n2. Táº¡o Precise Voice Detector...")
    detector_success = create_precise_voice_detector()
    
    # Káº¿t quáº£
    print("\n=== KET QUA ===")
    print(f"Precise Analysis: {'OK' if precise_analysis is not None else 'ERROR'}")
    print(f"Detector Creation: {'OK' if detector_success else 'ERROR'}")
    
    if precise_analysis is not None and detector_success:
        print("\nDA PHAN TICH CHINH XAC VI TRI GIONG HAT!")
    else:
        print("\nCAN CAI THIEN THEM!")
