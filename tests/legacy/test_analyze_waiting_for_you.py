#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test Analyze Waiting For You - Ph√¢n t√≠ch chi ti·∫øt v·ªã tr√≠ gi·ªçng h√°t th·ª±c s·ª±
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import logging
import librosa
import numpy as np
import matplotlib.pyplot as plt

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def analyze_waiting_for_you_detailed():
    """Ph√¢n t√≠ch chi ti·∫øt file Waiting For You ƒë·ªÉ t√¨m v·ªã tr√≠ gi·ªçng h√°t th·ª±c s·ª±"""
    try:
        # Test file Waiting For You
        test_file = "C:\\Users\\admin\\Downloads\\Waiting For You.mp3"
        
        if not os.path.exists(test_file):
            logger.error(f"Test file kh√¥ng t·ªìn t·∫°i: {test_file}")
            return False
        
        logger.info("üîç Ph√¢n t√≠ch chi ti·∫øt file Waiting For You...")
        logger.info(f"File: {test_file}")
        
        # Load audio
        audio, sr = librosa.load(test_file, sr=22050)
        duration = len(audio) / sr
        
        logger.info(f"Audio info: {duration:.2f}s, {sr} Hz, {len(audio)} samples")
        
        # Ph√¢n t√≠ch chi ti·∫øt t·ª´ng gi√¢y
        hop_length = 512
        frame_length = 2048
        
        # T√≠nh c√°c features
        rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr, hop_length=hop_length)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, hop_length=hop_length)[0]
        zcr = librosa.feature.zero_crossing_rate(audio, frame_length=frame_length, hop_length=hop_length)[0]
        
        # Chuy·ªÉn frames th√†nh th·ªùi gian
        times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
        
        # Ph√¢n t√≠ch t·ª´ng gi√¢y ƒë·ªÉ t√¨m v·ªã tr√≠ gi·ªçng h√°t th·ª±c s·ª±
        logger.info(f"\nüìä Ph√¢n t√≠ch t·ª´ng gi√¢y ƒë·ªÉ t√¨m gi·ªçng h√°t th·ª±c s·ª±:")
        
        # Ph√¢n t√≠ch 60 gi√¢y ƒë·∫ßu (ƒë·ªß ƒë·ªÉ t√¨m gi·ªçng h√°t)
        for i in range(min(60, len(rms))):
            start_time = i * hop_length / sr
            end_time = min((i + 1) * hop_length / sr, duration)
            
            # L·∫•y features c·ªßa gi√¢y n√†y
            segment_rms = rms[i]
            segment_centroid = spectral_centroids[i]
            segment_rolloff = spectral_rolloff[i]
            segment_zcr = zcr[i]
            
            # Ph√¢n t√≠ch harmonic content
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # Harmonic-percussive separation
            try:
                harmonic, percussive = librosa.effects.hpss(segment_audio)
                harmonic_energy = np.mean(np.abs(harmonic))
                percussive_energy = np.mean(np.abs(percussive))
                harmonic_ratio = harmonic_energy / (harmonic_energy + percussive_energy + 1e-8)
            except:
                harmonic_ratio = 0.5
            
            # MFCC ƒë·ªÉ ph√°t hi·ªán voice characteristics
            try:
                mfccs = librosa.feature.mfcc(y=segment_audio, sr=sr, n_mfcc=13)
                mfcc_mean = np.mean(mfccs[0])
                mfcc_std = np.std(mfccs[0])
            except:
                mfcc_mean = 0
                mfcc_std = 0
            
            # ƒêi·ªÅu ki·ªán ƒë·ªÉ x√°c ƒë·ªãnh c√≥ gi·ªçng h√°t (thresholds th·∫•p h∆°n)
            has_voice = (
                segment_rms > 0.05 and  # Energy ƒë·ªß cao (gi·∫£m threshold)
                segment_centroid > 800 and segment_centroid < 5000 and  # Voice frequency range r·ªông h∆°n
                segment_rolloff > 800 and  # C√≥ high frequency content (gi·∫£m threshold)
                harmonic_ratio > 0.3 and  # Harmonic content (gi·∫£m threshold)
                mfcc_std > 10  # MFCC variation (gi·∫£m threshold)
            )
            
            # Log chi ti·∫øt cho 30 gi√¢y ƒë·∫ßu
            if start_time < 30:
                logger.info(f"   {start_time:.1f}s: RMS={segment_rms:.4f}, Centroid={segment_centroid:.1f}Hz, Rolloff={segment_rolloff:.1f}Hz, Harmonic={harmonic_ratio:.3f}, MFCC_std={mfcc_std:.1f}, Voice={'YES' if has_voice else 'NO'}")
            
            # T√¨m v·ªã tr√≠ gi·ªçng h√°t ƒë·∫ßu ti√™n
            if has_voice and start_time > 5.0:  # B·ªè qua 5 gi√¢y ƒë·∫ßu (c√≥ th·ªÉ l√† intro)
                logger.info(f"\nüéØ T√¨m th·∫•y gi·ªçng h√°t th·ª±c s·ª± t·∫°i: {start_time:.2f}s")
                logger.info(f"   RMS: {segment_rms:.4f}")
                logger.info(f"   Centroid: {segment_centroid:.1f}Hz")
                logger.info(f"   Harmonic ratio: {harmonic_ratio:.3f}")
                return start_time
        
        logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y gi·ªçng h√°t trong 60 gi√¢y ƒë·∫ßu!")
        return None
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói ph√¢n t√≠ch: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_manual_voice_detection():
    """Test voice detection th·ªß c√¥ng v·ªõi thresholds th·∫•p"""
    try:
        # Test file Waiting For You
        test_file = "C:\\Users\\admin\\Downloads\\Waiting For You.mp3"
        
        if not os.path.exists(test_file):
            logger.error(f"Test file kh√¥ng t·ªìn t·∫°i: {test_file}")
            return False
        
        logger.info("üéØ Test voice detection th·ªß c√¥ng...")
        
        # Load audio
        audio, sr = librosa.load(test_file, sr=22050)
        
        # Ph√¢n t√≠ch t·ª´ng gi√¢y
        hop_length = 512
        frame_length = 2048
        
        # T√≠nh RMS energy
        rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]
        
        # T√≠nh baseline t·ª´ 5 gi√¢y ƒë·∫ßu
        baseline_length = min(5, len(rms))
        baseline_rms = np.mean(rms[:baseline_length])
        
        logger.info(f"üìä Baseline RMS: {baseline_rms:.4f}")
        
        # T√¨m v·ªã tr√≠ gi·ªçng h√°t v·ªõi thresholds th·∫•p
        voice_start_candidates = []
        
        # Ph√¢n t√≠ch 60 gi√¢y ƒë·∫ßu
        for i in range(min(60, len(rms))):
            start_time = i * hop_length / sr
            segment_rms = rms[i]
            
            # ƒêi·ªÅu ki·ªán ƒë∆°n gi·∫£n: RMS cao h∆°n baseline + 5%
            threshold = baseline_rms * 1.05  # Ch·ªâ c·∫ßn cao h∆°n 5%
            has_voice = segment_rms > threshold
            
            if has_voice:
                voice_start_candidates.append({
                    'time': start_time,
                    'rms': segment_rms,
                    'confidence': segment_rms / baseline_rms
                })
            
            # Log chi ti·∫øt cho 30 gi√¢y ƒë·∫ßu
            if start_time < 30:
                logger.info(f"   {start_time:.1f}s: RMS={segment_rms:.4f}, Threshold={threshold:.4f}, Voice={'YES' if has_voice else 'NO'}")
        
        # T√¨m v·ªã tr√≠ gi·ªçng h√°t b·∫Øt ƒë·∫ßu th·ª±c s·ª±
        if voice_start_candidates:
            # L·∫•y v·ªã tr√≠ ƒë·∫ßu ti√™n c√≥ voice sau 5 gi√¢y
            for candidate in voice_start_candidates:
                if candidate['time'] > 5.0:
                    logger.info(f"\nüéØ V·ªã tr√≠ gi·ªçng h√°t th·ª±c s·ª±: {candidate['time']:.2f}s")
                    logger.info(f"   RMS: {candidate['rms']:.4f}")
                    logger.info(f"   Confidence: {candidate['confidence']:.3f}")
                    return candidate['time']
        
        logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y v·ªã tr√≠ gi·ªçng h√°t!")
        return None
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói test: {e}")
        return None

if __name__ == "__main__":
    print("=== TEST ANALYZE WAITING FOR YOU ===")
    
    # Ph√¢n t√≠ch chi ti·∫øt
    print("\n1. Ph√¢n t√≠ch chi ti·∫øt file Waiting For You...")
    detailed_analysis = analyze_waiting_for_you_detailed()
    
    # Test voice detection th·ªß c√¥ng
    print("\n2. Test voice detection th·ªß c√¥ng...")
    manual_detection = test_manual_voice_detection()
    
    # K·∫øt qu·∫£
    print("\n=== KET QUA ===")
    print(f"Detailed Analysis: {'OK' if detailed_analysis is not None else 'ERROR'}")
    print(f"Manual Detection: {'OK' if manual_detection is not None else 'ERROR'}")
    
    if detailed_analysis is not None:
        print(f"\nüéØ Gi·ªçng h√°t th·ª±c s·ª± b·∫Øt ƒë·∫ßu t·∫°i: {detailed_analysis:.2f}s")
    elif manual_detection is not None:
        print(f"\nüéØ Gi·ªçng h√°t th·ª±c s·ª± b·∫Øt ƒë·∫ßu t·∫°i: {manual_detection:.2f}s")
    else:
        print("\n‚ö†Ô∏è C·∫ßn ph√¢n t√≠ch th√™m ƒë·ªÉ t√¨m v·ªã tr√≠ gi·ªçng h√°t!")
