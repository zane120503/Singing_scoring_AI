#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Accurate Voice Detector - Ph√°t hi·ªán ch√≠nh x√°c gi·ªçng h√°t trong file karaoke
"""

import os
import sys
import numpy as np
import librosa
import logging
from typing import Dict, List, Tuple, Optional
from pathlib import Path

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

logger = logging.getLogger(__name__)

class AccurateVoiceDetector:
    """Accurate Voice Detector - Ph√°t hi·ªán ch√≠nh x√°c gi·ªçng h√°t trong file karaoke"""
    
    def __init__(self, sr: int = 22050):
        self.sr = sr
        self.frame_length = 2048
        self.hop_length = 512
    
    def detect_voice_activity(self, audio_path: str) -> List[Dict]:
        """Ph√°t hi·ªán voice activity v·ªõi ƒë·ªô ch√≠nh x√°c cao"""
        try:
            logger.info("üéØ Accurate Voice Detection...")
            
            # Load audio
            audio, sr = librosa.load(audio_path, sr=self.sr)
            
            # Convert to mono if stereo
            if len(audio.shape) > 1:
                audio = librosa.to_mono(audio)
            
            # Ph√¢n t√≠ch ƒë·ªÉ t√¨m v·ªã tr√≠ gi·ªçng h√°t th·ª±c s·ª±
            voice_start = self._find_accurate_voice_start(audio, sr)
            
            if voice_start is None:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y v·ªã tr√≠ gi·ªçng h√°t")
                return []
            
            # T·∫°o segment t·ª´ v·ªã tr√≠ t√¨m ƒë∆∞·ª£c
            segments = [{
                'start': voice_start,
                'end': len(audio) / sr,  # ƒê·∫øn cu·ªëi file
                'confidence': 1.0,
                'method': 'accurate_detection'
            }]
            
            logger.info(f"‚úÖ Accurate voice detection: {len(segments)} segments")
            logger.info(f"   Voice starts at: {voice_start:.2f}s")
            
            return segments
            
        except Exception as e:
            logger.error(f"‚ùå Accurate voice detection failed: {e}")
            return []
    
    def _find_accurate_voice_start(self, audio: np.ndarray, sr: int) -> Optional[float]:
        """T√¨m v·ªã tr√≠ b·∫Øt ƒë·∫ßu gi·ªçng h√°t th·ª±c s·ª±"""
        try:
            # Ph√¢n t√≠ch t·ª´ng gi√¢y
            hop_length = self.hop_length
            
            # T√≠nh RMS energy
            rms = librosa.feature.rms(y=audio, frame_length=self.frame_length, hop_length=hop_length)[0]
            
            # T√≠nh spectral features
            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr, hop_length=hop_length)[0]
            spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, hop_length=hop_length)[0]
            zcr = librosa.feature.zero_crossing_rate(audio, frame_length=self.frame_length, hop_length=hop_length)[0]
            
            # Chuy·ªÉn frames th√†nh th·ªùi gian
            times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
            
            logger.info(f"üîç Ph√¢n t√≠ch {len(rms)} frames ƒë·ªÉ t√¨m gi·ªçng h√°t th·ª±c s·ª±...")
            
            # T√≠nh baseline t·ª´ 20 gi√¢y ƒë·∫ßu (intro)
            baseline_length = min(20, len(rms))
            baseline_rms = np.mean(rms[:baseline_length])
            baseline_centroid = np.mean(spectral_centroids[:baseline_length])
            baseline_rolloff = np.mean(spectral_rolloff[:baseline_length])
            baseline_zcr = np.mean(zcr[:baseline_length])
            
            logger.info(f"üìä Baseline analysis:")
            logger.info(f"   RMS: {baseline_rms:.4f}")
            logger.info(f"   Centroid: {baseline_centroid:.1f} Hz")
            logger.info(f"   Rolloff: {baseline_rolloff:.1f} Hz")
            logger.info(f"   ZCR: {baseline_zcr:.4f}")
            
            # T√¨m v·ªã tr√≠ gi·ªçng h√°t v·ªõi logic ch√≠nh x√°c
            voice_start_candidates = []
            
            # Ph√¢n t√≠ch 120 gi√¢y ƒë·∫ßu
            for i in range(min(120, len(rms))):
                start_time = i * hop_length / sr
                segment_rms = rms[i]
                segment_centroid = spectral_centroids[i]
                segment_rolloff = spectral_rolloff[i]
                segment_zcr = zcr[i]
                
                # Ph√¢n t√≠ch harmonic content
                start_sample = int(start_time * sr)
                end_sample = int(end_time * sr)
                segment_audio = audio[start_sample:end_sample]
                
                # Harmonic-percussive separation
                try:
                    harmonic, percussive = librosa.effects.hpss(segment_audio)
                    harmonic_energy = np.mean(np.abs(harmonic))
                    percussive_energy = np.mean(np.abs(percussive))
                    harmonic_ratio = harmonic_energy / (harmonic_energy + percussive_energy + 1e-8)
                except:
                    harmonic_ratio = 0.5
                
                # MFCC ƒë·ªÉ ph√°t hi·ªán voice characteristics
                try:
                    mfccs = librosa.feature.mfcc(y=segment_audio, sr=sr, n_mfcc=13)
                    mfcc_mean = np.mean(mfccs[0])
                    mfcc_std = np.std(mfccs[0])
                except:
                    mfcc_mean = 0
                    mfcc_std = 0
                
                # ƒêi·ªÅu ki·ªán ch√≠nh x√°c ƒë·ªÉ x√°c ƒë·ªãnh c√≥ gi·ªçng h√°t
                has_voice = (
                    segment_rms > baseline_rms * 1.5 and  # Energy cao h∆°n baseline 50%
                    segment_centroid > baseline_centroid * 0.8 and segment_centroid < 4000 and  # Voice frequency range
                    segment_rolloff > baseline_rolloff * 0.8 and  # C√≥ high frequency content
                    harmonic_ratio > 0.7 and  # Harmonic content cao (voice c√≥ harmonic)
                    mfcc_std > 30  # MFCC variation (voice c√≥ variation)
                )
                
                if has_voice:
                    voice_start_candidates.append({
                        'time': start_time,
                        'rms': segment_rms,
                        'centroid': segment_centroid,
                        'rolloff': segment_rolloff,
                        'harmonic_ratio': harmonic_ratio,
                        'mfcc_std': mfcc_std,
                        'confidence': self._calculate_voice_confidence(segment_rms, segment_centroid, harmonic_ratio, mfcc_std, baseline_rms, baseline_centroid)
                    })
                
                # Log chi ti·∫øt cho 30 gi√¢y ƒë·∫ßu
                if start_time < 30:
                    logger.info(f"   {start_time:.1f}s: RMS={segment_rms:.4f}, Centroid={segment_centroid:.1f}Hz, Rolloff={segment_rolloff:.1f}Hz, Harmonic={harmonic_ratio:.3f}, MFCC_std={mfcc_std:.1f}, Voice={'YES' if has_voice else 'NO'}")
            
            # T√¨m v·ªã tr√≠ gi·ªçng h√°t b·∫Øt ƒë·∫ßu th·ª±c s·ª±
            if voice_start_candidates:
                # L·∫•y v·ªã tr√≠ c√≥ confidence cao nh·∫•t
                best_candidate = max(voice_start_candidates, key=lambda x: x['confidence'])
                
                logger.info(f"\nüéØ V·ªã tr√≠ gi·ªçng h√°t ch√≠nh x√°c:")
                logger.info(f"   Voice starts at: {best_candidate['time']:.2f}s")
                logger.info(f"   Confidence: {best_candidate['confidence']:.3f}")
                logger.info(f"   RMS: {best_candidate['rms']:.4f}")
                logger.info(f"   Centroid: {best_candidate['centroid']:.1f}Hz")
                logger.info(f"   Harmonic ratio: {best_candidate['harmonic_ratio']:.3f}")
                
                return best_candidate['time']
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y v·ªã tr√≠ gi·ªçng h√°t!")
                return None
        
        except Exception as e:
            logger.error(f"‚ùå L·ªói t√¨m v·ªã tr√≠ gi·ªçng h√°t: {e}")
            return None
    
    def _calculate_voice_confidence(self, rms: float, centroid: float, harmonic_ratio: float, mfcc_std: float, baseline_rms: float, baseline_centroid: float) -> float:
        """T√≠nh confidence score cho voice detection v·ªõi baseline"""
        try:
            # Normalize c√°c features d·ª±a tr√™n baseline
            rms_score = min((rms - baseline_rms) / baseline_rms, 1.0)  # So v·ªõi baseline
            centroid_score = 1.0 - abs(centroid - baseline_centroid) / baseline_centroid  # So v·ªõi baseline
            harmonic_score = harmonic_ratio  # ƒê√£ normalize
            mfcc_score = min(mfcc_std / 50, 1.0)  # Normalize MFCC std
            
            # Weighted average
            confidence = (
                max(rms_score, 0) * 0.4 +  # TƒÉng weight cho RMS
                max(centroid_score, 0) * 0.3 +
                harmonic_score * 0.2 +
                mfcc_score * 0.1
            )
            
            return confidence
            
        except Exception as e:
            logger.warning(f"Confidence calculation failed: {e}")
            return 0.5
    
    def get_first_suitable_voice_segment(self, audio_path: str, min_duration: float = 1.0) -> Dict:
        """Returns the first voice segment that meets a minimum duration."""
        segments = self.detect_voice_activity(audio_path)
        for segment in segments:
            if (segment['end'] - segment['start']) >= min_duration:
                logger.info(f"‚úÖ Found first suitable accurate voice segment: {segment['start']:.2f}s - {segment['end']:.2f}s")
                return segment
        logger.warning("‚ö†Ô∏è No suitable accurate voice segment found.")
        return None
