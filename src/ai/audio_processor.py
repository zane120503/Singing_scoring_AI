import torch
import torchaudio
import librosa
import soundfile as sf
import numpy as np
from transformers import AutoProcessor, AutoModel
import os
import logging
from typing import Tuple, Optional

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AudioProcessor:
    """X·ª≠ l√Ω √¢m thanh v√† t√°ch gi·ªçng h√°t s·ª≠ d·ª•ng AI Audio Separator"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.processor = None
        self._load_model()
    
    def _load_model(self):
        """T·∫£i model AI Audio Separator t·ª´ Hugging Face"""
        try:
            logger.info("üîÑ ƒêang t·∫£i model AI Audio Separator...")
            logger.info(f"üì± Device: {self.device}")
            
            # S·ª≠ d·ª•ng model c√≥ s·∫µn v√† ho·∫°t ƒë·ªông t·ªët
            model_name = "facebook/wav2vec2-base-960h"
            logger.info(f"ü§ñ Model name: {model_name}")
            
            logger.info("üì• ƒêang t·∫£i processor...")
            self.processor = AutoProcessor.from_pretrained(model_name)
            logger.info("‚úÖ Processor loaded successfully!")
            
            logger.info("üì• ƒêang t·∫£i model...")
            self.model = AutoModel.from_pretrained(model_name).to(self.device)
            logger.info("‚úÖ Model loaded successfully!")
            
            logger.info("üéâ AI Audio Separator model ƒë√£ s·∫µn s√†ng!")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫£i model AI: {e}")
            logger.warning("‚ö†Ô∏è S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p fallback v·ªõi librosa...")
            # Fallback s·ª≠ d·ª•ng librosa ƒë·ªÉ t√°ch gi·ªçng ƒë∆°n gi·∫£n
            self.model = None
            self.processor = None
    
    def load_audio(self, file_path: str, sample_rate: int = 44100) -> Tuple[np.ndarray, int]:
        """T·∫£i file √¢m thanh"""
        try:
            audio, sr = librosa.load(file_path, sr=sample_rate)
            return audio, sr
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫£i file √¢m thanh: {e}")
    
    def separate_vocals(self, audio_path: str, output_path: Optional[str] = None) -> str:
        """T√°ch gi·ªçng h√°t t·ª´ file karaoke"""
        try:
            logger.info(f"üé§ B·∫Øt ƒë·∫ßu t√°ch gi·ªçng t·ª´ file: {audio_path}")
            
            # T·∫£i √¢m thanh
            logger.info("üì• ƒêang t·∫£i file √¢m thanh...")
            audio, sr = self.load_audio(audio_path)
            logger.info(f"‚úÖ ƒê√£ t·∫£i audio: {len(audio)} samples, {sr} Hz")
            
            if self.model is not None:
                logger.info("ü§ñ S·ª≠ d·ª•ng AI model ƒë·ªÉ t√°ch gi·ªçng...")
                vocals = self._separate_with_ai(audio, sr)
                logger.info("‚úÖ AI separation ho√†n th√†nh!")
            else:
                logger.warning("‚ö†Ô∏è AI model kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng fallback v·ªõi librosa...")
                vocals = self._separate_with_librosa(audio, sr)
                logger.info("‚úÖ Librosa separation ho√†n th√†nh!")
            
            # L∆∞u file gi·ªçng ƒë√£ t√°ch v·ªõi ƒë·ªãnh d·∫°ng MP3
            if output_path is None:
                base_name = os.path.splitext(audio_path)[0]
                output_path = f"{base_name}_vocals.mp3"
            
            logger.info(f"üíæ ƒêang l∆∞u file gi·ªçng ƒë√£ t√°ch: {output_path}")
            
            # L∆∞u v·ªõi ƒë·ªãnh d·∫°ng MP3
            sf.write(output_path, vocals, sr, format='MP3')
            logger.info(f"‚úÖ ƒê√£ t√°ch gi·ªçng v√† l∆∞u t·∫°i: {output_path}")
            
            # Ki·ªÉm tra file ƒë√£ ƒë∆∞·ª£c t·∫°o
            if os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                logger.info(f"üìä K√≠ch th∆∞·ªõc file: {file_size / 1024 / 1024:.2f} MB")
            
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t√°ch gi·ªçng: {e}")
            raise Exception(f"L·ªói khi t√°ch gi·ªçng: {e}")
    
    def _separate_with_ai(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """T√°ch gi·ªçng s·ª≠ d·ª•ng AI model"""
        try:
            logger.info("üîÑ ƒêang x·ª≠ l√Ω v·ªõi AI model...")
            
            # Chuy·ªÉn ƒë·ªïi audio th√†nh tensor
            audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)
            logger.info(f"üìä Audio tensor shape: {audio_tensor.shape}")
            
            # X·ª≠ l√Ω v·ªõi model
            logger.info("ü§ñ ƒêang ch·∫°y AI model...")
            with torch.no_grad():
                separated = self.model(audio_tensor)
                vocals = separated[0, 0].cpu().numpy()  # L·∫•y track gi·ªçng h√°t
                logger.info(f"‚úÖ AI model output shape: {vocals.shape}")
            
            return vocals
        except Exception as e:
            logger.error(f"‚ùå L·ªói AI separation: {e}")
            logger.warning("‚ö†Ô∏è Chuy·ªÉn sang ph∆∞∆°ng ph√°p fallback...")
            return self._separate_with_librosa(audio, sr)
    
    def _separate_with_librosa(self, audio: np.ndarray, sr: int) -> np.ndarray:
        """T√°ch gi·ªçng s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n v·ªõi librosa"""
        try:
            logger.info("üîÑ S·ª≠ d·ª•ng librosa harmonic-percussive separation...")
            
            # S·ª≠ d·ª•ng harmonic-percussive separation
            harmonic, percussive = librosa.effects.hpss(audio)
            logger.info(f"üìä Harmonic shape: {harmonic.shape}, Percussive shape: {percussive.shape}")
            
            # Harmonic component th∆∞·ªùng ch·ª©a gi·ªçng h√°t
            vocals = harmonic
            
            # Normalize audio
            vocals = librosa.util.normalize(vocals)
            logger.info("‚úÖ Librosa separation ho√†n th√†nh!")
            
            return vocals
        except Exception as e:
            logger.error(f"‚ùå L·ªói librosa separation: {e}")
            logger.warning("‚ö†Ô∏è Tr·∫£ v·ªÅ audio g·ªëc...")
            return audio  # Tr·∫£ v·ªÅ audio g·ªëc n·∫øu kh√¥ng t√°ch ƒë∆∞·ª£c
    
    def get_audio_features(self, audio_path: str) -> dict:
        """Tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng √¢m thanh"""
        try:
            audio, sr = self.load_audio(audio_path)
            
            # T√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng
            features = {
                'duration': len(audio) / sr,
                'sample_rate': sr,
                'rms_energy': np.sqrt(np.mean(audio**2)),
                'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(audio)[0]),
                'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio, sr=sr)[0]),
                'spectral_rolloff': np.mean(librosa.feature.spectral_rolloff(y=audio, sr=sr)[0]),
                'mfcc': np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13), axis=1)
            }
            
            return features
        except Exception as e:
            raise Exception(f"L·ªói khi tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng: {e}")
    
    def normalize_audio(self, audio: np.ndarray) -> np.ndarray:
        """Chu·∫©n h√≥a √¢m thanh"""
        return librosa.util.normalize(audio)
    
    def trim_silence(self, audio: np.ndarray, sr: int, top_db: int = 20) -> np.ndarray:
        """Lo·∫°i b·ªè kho·∫£ng l·∫∑ng"""
        trimmed, _ = librosa.effects.trim(audio, top_db=top_db)
        return trimmed
