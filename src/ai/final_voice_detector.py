#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Final Voice Detector - PhÃ¡t hiá»‡n giá»ng hÃ¡t cuá»‘i cÃ¹ng vá»›i logic Ä‘Æ¡n giáº£n
"""

import os
import sys
import numpy as np
import librosa
import logging
from typing import Dict, List, Tuple, Optional
from pathlib import Path

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

logger = logging.getLogger(__name__)

class FinalVoiceDetector:
    """Final Voice Detector - PhÃ¡t hiá»‡n giá»ng hÃ¡t cuá»‘i cÃ¹ng vá»›i logic Ä‘Æ¡n giáº£n"""
    
    def __init__(self, sr: int = 22050):
        self.sr = sr
        self.frame_length = 2048
        self.hop_length = 512
    
    def detect_voice_activity(self, audio_path: str) -> List[Dict]:
        """PhÃ¡t hiá»‡n voice activity vá»›i logic cuá»‘i cÃ¹ng"""
        try:
            logger.info("ğŸ¯ Final Voice Detection...")
            
            # Load audio
            audio, sr = librosa.load(audio_path, sr=self.sr)
            
            # Convert to mono if stereo
            if len(audio.shape) > 1:
                audio = librosa.to_mono(audio)
            
            # PhÃ¢n tÃ­ch Ä‘Æ¡n giáº£n Ä‘á»ƒ tÃ¬m vá»‹ trÃ­ giá»ng hÃ¡t
            voice_start = self._find_final_voice_start(audio, sr)
            
            if voice_start is None:
                logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y vá»‹ trÃ­ giá»ng hÃ¡t")
                return []
            
            # Táº¡o segment tá»« vá»‹ trÃ­ tÃ¬m Ä‘Æ°á»£c
            segments = [{
                'start': voice_start,
                'end': len(audio) / sr,  # Äáº¿n cuá»‘i file
                'confidence': 1.0,
                'method': 'final_detection'
            }]
            
            logger.info(f"âœ… Final voice detection: {len(segments)} segments")
            logger.info(f"   Voice starts at: {voice_start:.2f}s")
            
            return segments
            
        except Exception as e:
            logger.error(f"âŒ Final voice detection failed: {e}")
            return []
    
    def _find_final_voice_start(self, audio: np.ndarray, sr: int) -> Optional[float]:
        """TÃ¬m vá»‹ trÃ­ báº¯t Ä‘áº§u giá»ng hÃ¡t báº±ng logic cuá»‘i cÃ¹ng"""
        try:
            # PhÃ¢n tÃ­ch tá»«ng giÃ¢y
            hop_length = self.hop_length
            
            # TÃ­nh RMS energy
            rms = librosa.feature.rms(y=audio, frame_length=self.frame_length, hop_length=hop_length)[0]
            
            # Chuyá»ƒn frames thÃ nh thá»i gian
            times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
            
            logger.info(f"ğŸ” PhÃ¢n tÃ­ch {len(rms)} frames Ä‘á»ƒ tÃ¬m giá»ng hÃ¡t...")
            
            # TÃ­nh baseline tá»« 2 giÃ¢y Ä‘áº§u
            baseline_length = min(2, len(rms))
            baseline_rms = np.mean(rms[:baseline_length])
            
            logger.info(f"ğŸ“Š Baseline analysis:")
            logger.info(f"   RMS mean: {baseline_rms:.4f}")
            
            # TÃ¬m vá»‹ trÃ­ giá»ng hÃ¡t vá»›i logic Ä‘Æ¡n giáº£n - threshold tháº¥p
            voice_start_candidates = []
            
            # PhÃ¢n tÃ­ch 15 giÃ¢y Ä‘áº§u
            for i in range(min(15, len(rms))):
                start_time = i * hop_length / sr
                segment_rms = rms[i]
                
                # Äiá»u kiá»‡n Ä‘Æ¡n giáº£n: RMS cao hÆ¡n baseline + 10%
                threshold = baseline_rms * 1.1  # Chá»‰ cáº§n cao hÆ¡n 10%
                has_voice = segment_rms > threshold
                
                if has_voice:
                    voice_start_candidates.append({
                        'time': start_time,
                        'rms': segment_rms,
                        'confidence': segment_rms / baseline_rms
                    })
                
                # Log chi tiáº¿t cho 10 giÃ¢y Ä‘áº§u
                if start_time < 10:
                    logger.info(f"   {start_time:.1f}s: RMS={segment_rms:.4f}, Threshold={threshold:.4f}, Voice={'YES' if has_voice else 'NO'}")
            
            # TÃ¬m vá»‹ trÃ­ giá»ng hÃ¡t báº¯t Ä‘áº§u thá»±c sá»±
            if voice_start_candidates:
                # Láº¥y vá»‹ trÃ­ Ä‘áº§u tiÃªn cÃ³ voice
                first_voice = voice_start_candidates[0]
                
                logger.info(f"\nğŸ¯ Vá»‹ trÃ­ giá»ng hÃ¡t cuá»‘i cÃ¹ng:")
                logger.info(f"   Voice starts at: {first_voice['time']:.2f}s")
                logger.info(f"   RMS: {first_voice['rms']:.4f}")
                logger.info(f"   Confidence: {first_voice['confidence']:.3f}")
                
                return first_voice['time']
            else:
                logger.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y vá»‹ trÃ­ giá»ng hÃ¡t!")
                return None
        
        except Exception as e:
            logger.error(f"âŒ Lá»—i tÃ¬m vá»‹ trÃ­ giá»ng hÃ¡t: {e}")
            return None
    
    def get_first_suitable_voice_segment(self, audio_path: str, min_duration: float = 1.0) -> Dict:
        """Returns the first voice segment that meets a minimum duration."""
        segments = self.detect_voice_activity(audio_path)
        for segment in segments:
            if (segment['end'] - segment['start']) >= min_duration:
                logger.info(f"âœ… Found first suitable final voice segment: {segment['start']:.2f}s - {segment['end']:.2f}s")
                return segment
        logger.warning("âš ï¸ No suitable final voice segment found.")
        return None
